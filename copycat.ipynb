{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b86ceeeb",
   "metadata": {},
   "source": [
    "# Copycat\n",
    "\n",
    "In reading about GPT-3 I came across Melanie Mitchell's article [\"Can GPT-3 Make Analogies?\"](https://medium.com/@melaniemitchell.me/can-gpt-3-make-analogies-16436605c446). Both this article and [its follow-up](https://medium.com/@melaniemitchell.me/follow-up-to-can-gpt-3-make-analogies-b202204bd292) were written in August of 2020 and it seems GPT-3 has changed quite a bit since then. Most notably GPT-3 now offers four different models, each with their own tradeoffs between speed, cost, and capabilities. The most capable (and most expensive) model, `text-da-vinci-002`, uses training data from as recently as June of 2021. \n",
    "\n",
    "This made me curious: \n",
    "  1. With the changes to GPT-3, has its ability to solve letter-string analogy problems improved? \n",
    "  2. How does model selection affect performance?\n",
    "  3. How can fine-tuning be used to increase performance?\n",
    "  \n",
    "I'll start by feeding GPT-3 the same prompts Dr. Mitchell did (from the original article as well as its follow-up) using `text-da-vinci-002` through the OpenAI Python API. After that I'll try the other models and compare the results.\n",
    "\n",
    "If you'd like to run or modify this code you'll just need to get an OpenAI API key and set your OPENAI_API_KEY env variable to it. I'll try to keep track of the overall cost in credits as I go. Additionally, I've written some helper functions that will be kept in `gpt_helpers.py` so I don't clutter this notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "697a14b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject text_completion id=cmpl-5vNG1BTLGm721EOBXfCAHXnzyjUtN at 0x10d7a3a60> JSON: {\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"finish_reason\": \"stop\",\n",
       "      \"index\": 0,\n",
       "      \"logprobs\": null,\n",
       "      \"text\": \"\\n\\np q d\"\n",
       "    }\n",
       "  ],\n",
       "  \"created\": 1664355781,\n",
       "  \"id\": \"cmpl-5vNG1BTLGm721EOBXfCAHXnzyjUtN\",\n",
       "  \"model\": \"text-davinci-002\",\n",
       "  \"object\": \"text_completion\",\n",
       "  \"usage\": {\n",
       "    \"completion_tokens\": 5,\n",
       "    \"prompt_tokens\": 19,\n",
       "    \"total_tokens\": 24\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gpt_helpers import get_completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa473446",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('.env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "0d6f052415c956c4c8bd8689ceff4bee1ac327040edc7df8e3b40826f6a76426"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
