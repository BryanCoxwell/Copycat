{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b86ceeeb",
   "metadata": {},
   "source": [
    "# Copycat\n",
    "\n",
    "In reading about GPT-3 I came across Melanie Mitchell's article [\"Can GPT-3 Make Analogies?\"](https://medium.com/@melaniemitchell.me/can-gpt-3-make-analogies-16436605c446). Both this article and [its follow-up](https://medium.com/@melaniemitchell.me/follow-up-to-can-gpt-3-make-analogies-b202204bd292) were written in August of 2020 and it seems GPT-3 has changed quite a bit since then. Most notably GPT-3 now offers four different models, each with their own tradeoffs between speed, cost, and capabilities. The most capable (and most expensive) model, `text-da-vinci-002`, uses training data from as recently as June of 2021. \n",
    "\n",
    "This made me curious: \n",
    "  1. With the changes to GPT-3, has its ability to solve letter-string analogy problems improved? \n",
    "  2. How does model selection affect performance?\n",
    "  3. How can fine-tuning be used to increase performance?\n",
    "  \n",
    "I'll start by feeding GPT-3 the same prompts Dr. Mitchell did (from the original article as well as its follow-up) using `text-da-vinci-002` through the OpenAI Python API. I'll skip some prompts she used in situations where she needed to provide extra training examples if it seems like GPT-3 already \"gets it\". \n",
    "\n",
    "If you'd like to run or modify this code you'll just need to get an OpenAI API key and set your OPENAI_API_KEY env variable to it. I'll try to keep track of the overall cost in credits as I go. Additionally, I've written a few classes and helper functions in `gpt_helpers.py` to make iterating over different inputs a little easier. \n",
    "\n",
    "## How gpt_helpers.py works\n",
    "The `LetterStringAnalogySolver` class configures the parameters passed to GPT-3, formats input, and displays the response. Configurable GPT-3 parameters are limited to the model name (required) and temperature for now (`max_tokens` is set as a constant).\n",
    "The base prompt which the inputs are formatted into is also configurable. If not set it will default to:\n",
    "\n",
    "```\n",
    "\"Q: if {example_source} changes to {example_target} , what does {challenge_source} change to?\\nA: {challenge_target}\"\n",
    "```\n",
    "If modified, the only requirement on the base prompt is that it includes the same format variables `example_source`, `example_target`, `challenge_source`, and `challenge_target`.\n",
    "\n",
    "The input (prompt data) is a list of lists of strings which will be formatted (in order!) into the base prompt. Formatting includes inserting a space between each character (to avoid issues caused by GPT-3's byte-pair encoding), and cases are preserved. So, for example:\n",
    "```\n",
    "input = [\n",
    "    [\"aaa\", \"bbb\", \"ccc\", \"ddd\"],\n",
    "    [\"fff\", \"ggg\", \"hhh\", \"\"]\n",
    "  ]\n",
    "```\n",
    "would yield the prompt\n",
    "```\n",
    "Q: if a a a changes to b b b , what does c c c change to?\n",
    "A: d d d\n",
    "Q: if f f f changes to g g g , what does h h h change to?\n",
    "A:\n",
    "```\n",
    "Note that the last element of the last list is empty since we want GPT-3 to tell us what it thinks the `challenge_target` is. \n",
    "\n",
    "To pass the input to GPT-3 and receive a response, pass the prompt data to `LetterStringAnalogySolver.challenge()`.\n",
    "To run each request multiple times, set the `trials` parameter. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa82876c",
   "metadata": {},
   "source": [
    "### Setup\n",
    "I'm going to start with the model `text-davinci-002` as it's the most powerful, and I'll use the default temperature of 0.7 and run each prompt 5 times as Dr. Mitchell did. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "697a14b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gpt_helpers import LetterStringAnalogySolver, ModelName\n",
    "\n",
    "solver              = LetterStringAnalogySolver()\n",
    "solver.model        = ModelName.DAVINCI\n",
    "solver.temperature  = 0.7\n",
    "solver.trials       = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18712be3",
   "metadata": {},
   "source": [
    "### Experiment 1: Simple alphabetic sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa473446",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "Zero-shot\n",
    "Expected answer: p q s \n",
    "Original results:\n",
    "a b d\n",
    "p q r \n",
    "p q r\n",
    "c d\n",
    "a b c p q r a b c\n",
    "\"\"\"\n",
    "ex1_1_input = [\n",
    "    [\"abc\", \"abd\", \"pqr\", \"\"]\n",
    "]\n",
    "solver.challenge(ex1_1_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55eb7e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "One-shot\n",
    "Expected answer: i j l \n",
    "Original results:\n",
    "i j l (each trial)\n",
    "\n",
    "\"\"\"\n",
    "ex1_2_input = [\n",
    "    [\"abc\", \"abd\", \"pqr\", \"pqs\"],\n",
    "    [\"abc\", \"abd\", \"ijk\", \"\"]\n",
    "]\n",
    "solver.challenge(ex1_2_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3b90034",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "Generalizing to different string lengths, zero-shot\n",
    "(Not in original article) \n",
    "Expected answer: i j k l n\n",
    "\"\"\"\n",
    "ex1_3_oneshot_input = [\n",
    "    [\"abc\", \"abd\", \"ijklm\", \"\"]\n",
    "]\n",
    "solver.challenge(ex1_3_oneshot_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c37a0748",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "Generalizing to different string lengths \n",
    "Expected answer: i j k l n\n",
    "Original results:\n",
    "i j l m\n",
    "i j k m\n",
    "i j m\n",
    "i j l\n",
    "i j k n\n",
    "\"\"\"\n",
    "ex1_3_input = [\n",
    "    [\"abc\", \"abd\", \"pqr\", \"pqs\"],\n",
    "    [\"abc\", \"abd\", \"ijklm\", \"\"],\n",
    "]\n",
    "solver.challenge(ex1_3_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "595f7ebd",
   "metadata": {},
   "source": [
    "### Experiment 2: Alphabetic sequences with grouping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff0cde54",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "Zero-shot \n",
    "Expected answer: i i j j l l\n",
    "Original response:\n",
    "Not shown, but they were all incorrect\n",
    "\"\"\"\n",
    "ex2_1_input = [\n",
    "    [\"abc\", \"abd\", \"iijjkk\", \"\"]\n",
    "]\n",
    "solver.challenge(ex2_1_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb3b37a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "One-shot\n",
    "Expected answer: m m n n p p \n",
    "Original response:\n",
    "m m n n p p (each trial)\n",
    "\"\"\"\n",
    "ex2_2_input = [\n",
    "    [\"abc\", \"abd\", \"iijjkk\", \"iijjll\"],\n",
    "    [\"abc\", \"abd\", \"mmnnoo\", \"\"]\n",
    "]\n",
    "solver.challenge(ex2_2_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a79a0280",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "Generalizing to different string lengths\n",
    "Expected answer: q q r r s s u u \n",
    "Original response: \n",
    "q q r r s s t t\n",
    "q q r r s s u u\n",
    "q q r r s s u u v\n",
    "q q r r s s t u\n",
    "q q r r s s u u v\n",
    "\"\"\"\n",
    "ex2_3_input = [\n",
    "    [\"abc\", \"abd\", \"iijjkk\", \"iijjll\"],\n",
    "    [\"abc\", \"abd\", \"qqrrsstt\", \"\"]\n",
    "]\n",
    "solver.challenge(ex2_3_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85024267",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "Providing two training examples \n",
    "Expected answer: e e f f g g h h j j\n",
    "Original response:\n",
    "e e f f g g h h j j\n",
    "e e f f g g i i\n",
    "e e f f g g i i j j\n",
    "e e f f g g h h i i\n",
    "e e f f g g i i\n",
    "\"\"\"\n",
    "ex2_4_input = [\n",
    "    [\"abc\", \"abd\", \"iijjkk\", \"iijjll\"],\n",
    "    [\"abc\", \"abd\", \"mmnnoopp\", \"mmnnooqq\"],\n",
    "    [\"abc\", \"abd\", \"eeffgghhii\", \"\"]\n",
    "]\n",
    "\n",
    "solver.challenge(ex2_4_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef1fab25",
   "metadata": {},
   "source": [
    "### Experiment 3: Cleaning up a string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38f61473",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "Zero-shot\n",
    "(Not in original article) \n",
    "Expected answer: m n o p q r \n",
    "\"\"\"\n",
    "ex3_1_zeroshot_input = [\n",
    "    [\"abbcde\", \"abcde\", \"mnoopqr\", \"\"]\n",
    "]\n",
    "solver.challenge(ex3_1_zeroshot_input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f94a27e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "One-shot \n",
    "Expected answer: m n o q p r \n",
    "Original response:\n",
    "m n o p q r\n",
    "m n o p q r\n",
    "m n p q r\n",
    "m n p q r \n",
    "m n o p q r\n",
    "\"\"\"\n",
    "ex3_1_input = [\n",
    "    [\"abbcde\", \"abcde\", \"pqrrst\", \"pqrst\"],\n",
    "    [\"abbcde\", \"abcde\", \"mnoopqr\", \"\"]\n",
    "]\n",
    "solver.challenge(ex3_1_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ccb4fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "Expected answer: m n o p \n",
    "Original response:\n",
    "m n o\n",
    "m n p\n",
    "m n o p\n",
    "m n o\n",
    "m n p\n",
    "\"\"\"\n",
    "ex3_2_input = [\n",
    "    [\"axbxcx\", \"abc\", \"pxqxxrx\", \"pqr\"],\n",
    "    [\"axbxcx\", \"abc\", \"rxsxtxx\", \"rst\"],\n",
    "    [\"axbxcx\", \"abc\", \"mxnxoxxp\", \"\"]\n",
    "]\n",
    "\n",
    "solver.challenge(ex3_2_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91146630",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "Using the character to be removed at the start of the target string\n",
    "Expected answer: i j k \n",
    "Original response:\n",
    "Not shown, but incorrect each time.\n",
    "\"\"\"\n",
    "ex3_5_input = [\n",
    "    [\"axbxcx\", \"abc\", \"pxqxxrx\", \"pqr\"],\n",
    "    [\"axbxcx\", \"abc\", \"rxsxtxx\", \"rst\"],\n",
    "    [\"axbxcx\", \"abc\", \"mxnxoxxp\", \"mnop\"],\n",
    "    [\"axbxcx\", \"abc\", \"xixxjxk\", \"\"]\n",
    "]\n",
    "solver.challenge(ex3_5_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1401367",
   "metadata": {},
   "source": [
    "### Experiment 4: Analogies involving abstract examples of \"successorship\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbfda93b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "Generalizing from letter-successor to abstract number successor \n",
    "Expected answer: j y y q q q q \n",
    "Original response:\n",
    "j y y r r r\n",
    "j y y q q r 2\n",
    "j y y q q q\n",
    "j y y r r r\n",
    "j y y q r\n",
    "\"\"\"\n",
    "ex4_1_input = [\n",
    "    [\"abc\", \"abd\", \"pqr\", \"pqs\"],\n",
    "    [\"abc\", \"abd\", \"ijklm\", \"ijkln\"],\n",
    "    [\"abc\", \"abd\", \"rstuvw\", \"rstuvx\"],\n",
    "    [\"abc\", \"abd\", \"jyyqqq\", \"\"],\n",
    "]\n",
    "solver.challenge(ex4_1_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a877926c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "Abstract numerical sequence \n",
    "Expected answer: b o o c c c v v v v\n",
    "Original response:\n",
    "b o o c c v v v v v v\n",
    "b o o c c v v v v v v v v v v v v v\n",
    "b o o c v v v\n",
    "b o b o c c c v v v v\n",
    "b o o c c c v v v v\n",
    "\"\"\"\n",
    "ex4_2_input = [\n",
    "    [\"qlg\", \"qllggg\", \"xmr\", \"xmmrrr\"],\n",
    "    [\"qlg\", \"qllggg\", \"rmqd\", \"rmmqqqdddd\"],\n",
    "    [\"qlg\", \"qllggg\", \"bocv\", \"\"]\n",
    "]\n",
    "solver.challenge(ex4_2_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e5df25",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "Replacing a substring with its successor \n",
    "Expected answer: s s t s t u v \n",
    "Original response:\n",
    "s s t s t u v (each trial)\n",
    "\"\"\"\n",
    "ex4_3_input = [\n",
    "    [\"abc\", \"abd\", \"aababc\", \"aababcd\"],\n",
    "    [\"abc\", \"abd\", \"ppqpqr\", \"ppqpqrs\"],\n",
    "    [\"abc\", \"abd\", \"sststu\", \"\"],\n",
    "]\n",
    "solver.challenge(ex4_3_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "465a716a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "Generalizing the above to different-length target strings \n",
    "Expected answer: e e f e f g e f g h i\n",
    "Original response:\n",
    "Not shown, but it got 4/5 correct.\n",
    "\"\"\"\n",
    "ex4_4_input = [\n",
    "    [\"abc\", \"abd\", \"aababc\", \"aababcd\"],\n",
    "    [\"abc\", \"abd\", \"ppqpqr\", \"ppqpqrs\"],\n",
    "    [\"abc\", \"abd\", \"eefefgefgh\", \"\"],\n",
    "]\n",
    "solver.challenge(ex4_4_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "857ab297",
   "metadata": {},
   "source": [
    "### Experiment 5: A letter with no successor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1223c3a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "A letter with no successor \n",
    "Expected answer: x y a \n",
    "Original results:\n",
    "x y a\n",
    "x y w\n",
    "x y b\n",
    "x z y\n",
    "x z b\n",
    "\"\"\"\n",
    "ex5_1_input = [\n",
    "    [\"abc\", \"abd\", \"pqr\", \"pqs\"],\n",
    "    [\"abc\", \"abd\", \"ijk\", \"ijl\"],\n",
    "    [\"abc\", \"abd\", \"xyz\", \"\"],\n",
    "]\n",
    "solver.challenge(ex5_1_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b4728e6",
   "metadata": {},
   "source": [
    "### Bonus: Follow-up\n",
    "One prompt from the follow-up article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d96373dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "Reversing a string \n",
    "Expected answer: v l q r y\n",
    "Original results:\n",
    "l q r y v\n",
    "r l y q v\n",
    "l y r q v\n",
    "r y l v q\n",
    "\"\"\"\n",
    "ex6_1_input = [\n",
    "    [\"mxq\", \"qxm\", \"pabm\", \"mbap\"],\n",
    "    [\"mxq\", \"qxm\", \"yrqlv\", \"\"],\n",
    "]\n",
    "solver.challenge(ex6_1_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e0621f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('.env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0b5"
  },
  "vscode": {
   "interpreter": {
    "hash": "0d6f052415c956c4c8bd8689ceff4bee1ac327040edc7df8e3b40826f6a76426"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
